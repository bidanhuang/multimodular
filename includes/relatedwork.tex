\section{Related Work}
\label{sec:related}
In this section, we review related literature in the area of robot learning manipulation task and modular approach.


%\subsection{Robot learning}
%\label{sec:imitation}
%Demonstration based learning has been an active topic of research in the last decade. While manually programming can be tedious, especially for unstructured and uncertain environment, program by demonstration (PbD) provide a way to speed up the process. It is designed to automatically extract key features and task constraints, which are invariance to environmental changes. This approach has been extensively studied in literatures~\cite{calinon2007learning,dillmann2004teaching,kulic2012incremental}.
%The approach of PbD usually goes through three stages: perceive (demonstration), recognise (skill modeling) and reproduction (task implementation)~\cite{demiris2002f}. The advantages of PbD largely come from the demonstration and skill modeling steps. In the later part of this section, we provide an overview on these two stages.

\subsection{Learning Manipulation Tasks}
Demonstration based learning has been extensively studied in literatures~\cite{calinon2007learning,dillmann2004teaching,kulic2012incremental} as a promising approach to build robot intelligence. %It is essential for the tasks that analytical expression of the system is hard to derive.
Learning manipulation tasks is one of the main application of this approach. The physical properties of a manipulation task is hard to express analytically, and hence the control strategy is hard to derive. Modeling expert's demonstration of good strategies is an alternative solution to manipulation tasks.

In learning manipulation tasks, kinematics teaching and tele-operation are two major forms of demonstration. In kinesthetic teaching, human directly contact with the robot and guide their movements to accomplish a task~\cite{korkinof2013online,pais2014encoding,pastor2011skill,Miao2014}. The trajectory of movements and contact force are recorded by the robot sensors.
% ===== Why not kinematics approach? =====
This method is simple and effective but limited in the number of controllable end effectors. While a manipulation task usually involves multifinger movement, a human can kinematically operate one finger with each hand and hence two fingers simultaneously for the most extend. To control multi-finger hands, some researchers use tele-operation~\cite{bernardino2013precision,kondo2008recognition,Fischer98}. This usually relies on data gloves and motion capture system to sense human hand-arm motions. The human motion is mapped to robots to generate motions and interact with the environment. In fine manipulation tasks, the robot platforms are usually restricted to anthropomorphic hands for better mapping. All of these methods provide no direct force feedback during manipulation to the human demonstrator.

In some studies, the human demonstrate manipulation tasks with their own bodies~\cite{asfour2008imitation}. With direct interaction with the object the human demonstrator is able to perform the task most naturally and with a more delicate control strategy. The task information captured from these human demonstrations is needed to be transferred to robots. Various mapping methods are proposed in many literatures~\cite{do2011towards,asfour2008imitation,hueser2006learning}, while human correction~\cite{calinon2007incremental,sauser2011iterative,romano2011human} and self-correction via learning~\cite{bidan2013robio} are proposed as alternative solutions. In general, how to effectively transfer human skill to robot skill remains a open problem.

In our approach, human perform the task with direct interaction with the object to allow them perform natural feedback control strategies. We transfer these strategies to robot by taking an object centric approach. The object centric viewpoint~\cite{okamura2000overview} considers a manipulation task from the object's perspective, which suggests the goal of learning a task is to reproduce the same object behaviour. Taking this principle, an object level approach is proposed in~\cite{Miao2014} to learn object impedance in grasping and manipulation tasks. Our approach takes the same principle and learns the control strategy to operate the objects that will produce the same object behaviour. This strategy expressed from the object perspective can be transfer to any robot platform.

The aim of an object centric approach is to learn the correlation between the exert force of the system and the desire object motion. A classic way to describe this correlation is impedance~\cite{howard2010transferring,wimbock2012comparison}. Giving  desired impedance of a task, we can compute proper motor commands for the robot to accomplish it. Computing the impedance for a given task is difficult, however, especially for the tasks involving variable impedance.
In many cases the impedance is roughly approximated by a linear model, but this is inadequate for nonlinear tasks. In~\cite{buchli2011learning} variable impedance is learn by the reinforcement learning algorithm $PI^2$ with a task specific cost function. Designing this cost function requires insight into the task and often is also laborious. 


<<<<<<< HEAD

% GMM
In our approach we take the advantage of human demonstration and we directly model the correlation of the exert force and the object motion by the Gaussian Mixture Model (GMM)~\cite{cohn1996active}. GMM has been shown to be an efficient model in capturing the nonlinearity of data~\cite{huang2013learning,sauser2011iterative,calinon2007incremental}. Our choice of GMM has other merits which will be discussed in later sections.
% benefit of using GMM will be discussed in later sections.

Single control strategy is inadequate for task with changing contexts.
Robots operating in human centric environment need to be equipped with multiple strategies to handle multiple contexts. In the next section we give a brief overview of the modular approach in control. 

=======
The aim of an object centric approach is to learn the correlation between the exert force of the system and the desire object motion. A classic way to describe this correlation is impedance~\cite{howard2010transferring,wimbock2012comparison}. Giving a desired impedance of a task, we can compute a proper motor command for the robot to accomplish the task. However the impedance is hard to specified in a given task, especially for task involving variable impedance. 
In most cases the impedance is roughly approximated by a linear model which is inadequate for nonlinear task. In~\cite{buchli2011learning} variable impedance is learn by the reinforcement learning algorithm $PI^2$ with a task specific cost function. Designing this cost function requires insight into the task and often is difficult. In our approach we take the advantage of human demonstration and we directly model the correlation of the exert force and the object motion by a nonlinear model.

% GMM
To capture the nonlinearity in the control strategy, we use the Gaussian Mixture Model (GMM)~\cite{cohn1996active} in our approach to encode the demonstration. GMM has been shown to be an efficient model in a variety of tasks~\cite{huang2013learning,sauser2011iterative,calinon2007incremental} and demonstrated to be effective. The benefit of using GMM will be discussed in later sections.
>>>>>>> 02b51e79a4c9f856083586a8b164b8e077f207df

\subsection{Modular Approach}
% Some manipulation modelling method. drawback. You must survey other approaches to model multiple sensori-motor loops (also called motor program, motor primitives, behaviors, etc) and switching across these models, and then justify the use of Mosaic

%% Internal model
%In the study of human motor control, internal model is one of the most evidently supported hypothesis. It postulates a neuron process that simulates output of the motor system and the environment~\cite{kawato1999internal}. It's applications in robot control have been explored by many researchers. Various types of internal models are built for different tasks~\cite{sciavicco2000modelling,jordan1992forward}.

% Adaptive
<<<<<<< HEAD
In manipulation tasks, context changing is a common phenomenon due to object interactions. These changes are often rapid or discontinuous. Classic adaptive control approaches such as model identification~\cite{khalil2004modeling} are inadequate for these tasks, as instability or error may occur during the searching of new optimal values of the model variables. A solution to fast adaption is the multiple model approach~\cite{narendra1995adaptation}. In this approach, multiple controllers are designed, each of which is appropriate for a certain task context. During control, the task context is estimated online and the corresponding controllers are activated. The benefit of this approach has been long discussed in the control community~\cite{jacobs1991adaptive,narendra1997adaptive}. Some recent works~\cite{fekri2007robust,kuipers2010multiple} present promising modular based approaches. Multiple model approach also has a wide range application in robot control. It has also been shown to be an effective architecture of building intelligent systems~\cite{bryson2004modular,BrysonMcG12}. It is particular useful for tasks in  non-stationary environment~\cite{sugimoto2012emosaic}.
=======
Robots operating in human centric environment need to handle tasks with changing contexts. These changes are often rapid or discontinuous. Classic adaptive control approaches such as model identification~\cite{khalil2004modeling} are inadequate for these tasks, as instability or error may occur during the period of searching new optimal model variable values. A solution to fast adaption is the multiple model approach. In this approach, multiple controllers are designed, each of which is appropriate for a certain task context. During control, the task context is estimated online and the corresponding controllers are activated. The benefit of this approach has been long discussed in the control community~\cite{jacobs1991adaptive,narendra1995adaptation,narendra1997adaptive}. Some recent works~\cite{fekri2007robust,kuipers2010multiple} present promising modular based approaches. Multiple model approach also has a wide range application in robot control. It has also been shown to be an effective architecture of building intelligent systems~\cite{bryson2004modular,BrysonMcG12}. It is particular useful for tasks in  non-stationary environment~\cite{petkos2006learning,sugimoto2012emosaic}.
>>>>>>> 02b51e79a4c9f856083586a8b164b8e077f207df

% Modular - human MOSAIC

%%The excellent ability of human to manipulate different objects in different contexts and to quickly adapt to change of contexts suggested that our central nervous system (CNS) maintains multiple internal models of outside environments, rather than a single internal model that adapts to new environment~\cite{neilson1985acquisition}.
%Based on the concept of modularity, the Modular selection and identification for control (MOSAIC) architecture was proposed to explain the motor control strategy of the CNS~\cite{wolpert1998multiple}. According to this hypothesis, during the motor control process, the brain quickly select the most appropriate modules according to the current environment context and use them to generate an appropriate motor command to react to the environment~\cite{haruno2001mosaic}.

% Our approach
The approach we take is a modular approach inspired from MOSAIC~\cite{haruno2001mosaic}. MOSCAIC (MOdular SeleCtion and Identification for Control) is a bio-inspired paradigm of multiple module control. Fig.~\ref{fig:control} illustrates the workflow. Each module is a pair of forward and inverse model. At each time step, the forward models estimate the current context and compare it with the actually context. The accuracy of the estimation decided the weight of the corresponding inverse models.
<<<<<<< HEAD
The final motor command is the linear combination of the commands generated from each inverse models factored by their weights. Compare to the switching modular method~\cite{narendra1997adaptive}, i.e. only one module will be activated and used to generate motor command, the linear combination of the modules requires less number of modules to approximate the system dynamics. 

In~\cite{petkos2006learning} the forward model and inverse model is united to a single one. This is because for that particular task there is always only one action ($a_t$) can map the current task state ($s_t$) to the desired task state ($s_{t+1}$). However, in many cases this mapping is not unique and hence the inverse model have to be built with extra variables to resolve the non-uniqueness. In our approach we build the forward and inverse model separately for each module.
%However this model does not provide a method to find out number of models needed in tasks. %and the inverse model represented by the joint distribution will potentially produce an invalid command that average all possible solutions.

Our approach is based on the MOSAIC paradigm but with different modeling methods: we use GMM to represent the forward and inverse model rather than neuron network (NN). The main reason is that neuron network can not directly estimate the likelihood of one query point. With NN, the the variance in each forward model, which is an essential variable to control how much the modules  cooperate, has to be hand tuned. Training GMM with the Expectation Maximization (EM) algorithm, we find the optimal values of the variances and hence avoid hand tuning.

Further, none of the modular approaches above provide a method to identify number of modules needed in a certain task. It is either predefined or defined by the number of different setups. We solve this problem by a data driven method. We cluster the demonstration data with an hierarchical approach and model each cluster as a module. This solution can be applied to find the number of modules for ``modularizable tasks''. To the best of our knowledge, this is the first realization of the multiple model in an object manipulation task with a real robot, learnt from human demonstration.

%Indeed, neuroscience evidence suggests that animal brain sum modular stimulates of muscles to generate different motions~\cite{mussa1994linear}.

=======
The final motor command is the linear combination of the commands generated from each inverse models factored by their weights. Compare to the switching modular method, i.e. only one module will be activated and used to generate motor command~\cite{narendra1997adaptive}, the linear combination of the modules requires less number of modules to approximate the system dynamics. In the case that there is always only one action ($a_t$) can map the current task state ($s_t$) to the desired task state ($s_{t+1}$), the forward model and inverse model can be united to a single joint distribution model of $\{s_{t+1}, s_t, a_t\}$~\cite{petkos2006learning}. In many cases, however, this mapping is not unique and the inverse model represented by the joint distribution will potentially produce an invalid command that average all possible solutions. For this reason, the inverse model have to be built with extra variables to resolve the non-uniqueness. In our approach we build the forward and inverse model separately for each module.
%However this model does not provide a method to find out number of models needed in tasks.

Our approach is based on the MOSAIC paradigm but different modeling methods: we use GMM to represent the forward and inverse model rather than neuron network (NN). The main reason is that neuron network can not directly estimate the likelihood of one query point. With NN, the the variance in each forward model has to be hand tuned, which is an essential variable as it decides how much the modules will cooperate. We train GMM with the Expectation Maximization (EM) algorithm, which will optimize the variances according to the data and hence avoid hand tuning.

Further, none of the modular approaches above provide a method to identify number of modules needed in a certain task. It is either predefined or defined by the number of different setups. In manipulation tasks, the number of modules is not easy to identify and we solve this problem by a data driven method. We cluster the demonstration data with an hierarchical approach and model each cluster as a module. This solution can be applied to find the number of modules for modularizable tasks. To the best of our knowledge, this is the first realization of the multiple model in an object manipulation task with a real robot, learnt from human demonstration.

%Indeed, neuroscience evidence suggests that animal brain sum modular stimulates of muscles to generate different motions~\cite{mussa1994linear}.

>>>>>>> 02b51e79a4c9f856083586a8b164b8e077f207df
%\textcolor{red}{TODO:compare with ANN(Note)}


%It is particularly useful to use learning to approximate internal models for motor control when the analytical model of the system dynamics is not easy to deduce.
%
%
%%Though the MOSAIC has gained a large concerns in neuroscience community, this approach is not widely used in robot control.
%
%Imitation learning has been an active topic of research in the last decade. It speeds up robot learning with the demonstrator showing the constraints of the tasks.

%The approach we take is a modular approach inspired from MOSAIC~\cite{haruno2001mosaic}. In MOSAIC, each dynamic system context is encoded by a pair of forward and inverse models. At each time step, the forward models estimate the current context and compare it with the actually context. The accuracy of the estimation decided the weight of the corresponding inverse models. The final motor command is the linear combination of the commands generated from each inverse models factored by their weights. The linear combination, rather than switch, of the models requires less number of models to approximate the system dynamics. Indeed, neuroscience evidence suggests that human brain mix modular stimulates of muscles to generate new motions. Our work focus on learning human's strategy of adaptive control on a modular base. To the best of our knowledge, this is the first realization of the multiple model control in an object manipulation task with a real robot, learnt from human demonstration.
%It can be used for solving nonlinear and non-stationary control problem.



%learning from human demonstration approach.


%
%Scientist has long been fascinated by human adaptive motor control ability and wondering the mechanism of it. One of the most evidently supported hypothesis is the multiple model~\cite{neilson1985acquisition}. %~\cite{haruno2001mosaic}


%(TODO: Joanna thinks this part can be extended. Please feel free to add any literatures that you think should be included. )
