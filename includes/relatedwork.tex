\section{Related Work}
\label{sec:related}
In this section, we give a overview of area of robot learning manipulation task and modular approaches.


%\subsection{Robot learning}
%\label{sec:imitation}
%Demonstration based learning has been an active topic of research in the last decade. While manually programming can be tedious, especially for unstructured and uncertain environment, program by demonstration (PbD) provide a way to speed up the process. It is designed to automatically extract key features and task constraints, which are invariance to environmental changes. This approach has been extensively studied in literatures~\citep{calinon2007learning,dillmann2004teaching,kulic2012incremental}.
%The approach of PbD usually goes through three stages: perceive (demonstration), recognise (skill modeling) and reproduction (task implementation)~\citep{demiris2002f}. The advantages of PbD largely come from the demonstration and skill modeling steps. In the later part of this section, we provide an overview on these two stages.

\subsection{Learning Manipulation Tasks}
Demonstration based learning has been extensively studied~\citep{calinon2007learning,dillmann2004teaching,kulic2012incremental} as a promising approach to build robot intelligence. %It is essential for the tasks that analytical expression of the system is hard to derive.
Learning manipulation tasks is one of the main application of this approach. The physical properties of a manipulation task is hard to express analytically, and as a result the control strategy is hard to derive. Modeling expert's demonstration of strategies has been used as an alternative to the analytical solution.

Two major forms of demonstration are used in teaching manipulation tasks: kinematics teaching and tele-operation. In kinesthetic teaching, human directly contact with the robot and guide their movements to accomplish a task~\citep{korkinof2013online,pais2014encoding,pastor2011skill,Miao2014}. The trajectory of movements and contact force are recorded by the robot sensors.
% ===== Why not kinematics approach? =====
This method is simple and effective but limited in the number of controllable end effectors. While a manipulation task usually involves multifinger movement, a human can kinematically operate one finger with each hand and hence two fingers simultaneously at most. To control multi-finger hands, some researchers use tele-operation~\citep{bernardino2013precision,kondo2008recognition,Fischer98}. This usually relies on data gloves and motion capture system to sense human hand-arm motions. The human motion is mapped to robots to generate motions and interact with the environment. In fine manipulation tasks, the robot platforms are usually restricted to anthropomorphic hands for better mapping. All of these methods provide no direct force feedback to the human demonstrator during manipulation.

In some studies, the human demonstrate manipulation tasks with their own bodies~\citep{asfour2008imitation}. With direct interaction with the object the human demonstrator is able to perform the task most naturally and with a more delicate control strategy. The task information captured from these human demonstrations needs to be transferred to robots. Various mapping methods have been proposed~\citep{hueser2006learning,asfour2008imitation,do2011towards,}, while human correction~\citep{calinon2007incremental,sauser2011iterative,romano2011human} and self-correction via learning~\citep{bidan2013robio} are proposed as alternative solutions. In general, how to effectively transfer human skills to robots skill remains a challenge.

We propose a method to allows the subject to perform natural feedback control strategies in demonstration, while the strategy can then be easily transfer to any robot platform. In our task demonstration, a human wears tactile sensors and directly interacts with objects. The demonstration is expressed from an object centric viewpoint. The object centric viewpoint~\citep{okamura2000overview,jain2013improving,Miao2014} considers a manipulation task from the object's perspective. This suggests that the goal of a manipulation task is to produce a desire object movement rather than a robot end-effector movement. Our approach takes this principle and learns a control strategy for producing a desired object behavior.
The demonstrated strategy expressed from the object perspective can then be transferred to a robot platform by covering the exert force to robot joint torque.

With the object centric viewpoint, we need to learn the correlation between the exerted force of the object and the desired object motion. A classic model of this correlation is impedance~\citep{howard2010transferring,wimbock2012comparison}. Given the desired impedance of a task, we can compute proper motor commands for the robot to accomplish it. Fix impedance control is limited to simple tasks. In many manipulation tasks such as opening a bottle cap, variable impedance is required: at the beginning we need a large impedance to break the contact between the bottle and the cap, and later we need a small impedance to drive the cap smoothly. For such tasks fix impedance control will either lead to task failure or cause hardware damage.
However, computing the impedance for a given task involving variable impedance is difficult.
In many cases the impedance is roughly approximated by a linear model, but this is inadequate for nonlinear tasks.


Variable impedance can be learnt by human physically correcting the robot impedance, i.e. wiggling the robot arm, in different stages of the task~\citep{kronander2012online}. For learning manipulation, however, wiggling the robot fingers will interrupt the task and may cause task failure.
%This is feasible for learning robot arm impedance but not for object impedance.
Variable impedance can also be learnt by the reinforcement learning algorithm Policy Improvement with Path Integrals ($PI^2$) with a task specific cost function~\citep{buchli2011learning}. Designing this cost function requires insight into the task and usually is difficult. In our approach, we directly model the correlation of the exerted force and the object motion by a nonlinear statistical model.


% GMM
%In our approach we directly model the correlation of the exerted force and the object motion using Gaussian Mixture Model (GMM)~\citep{cohn1996active}. GMM has been shown to be an efficient model in capturing the nonlinearity of data~\citep{huang2013learning,sauser2011iterative,calinon2007incremental}. Our choice of GMM has other merits which will be discussed in later sections.
% benefit of using GMM will be discussed in later sections.

Among the approaches mentioned above, single model is built for the entire task. For tasks involving of multiple phases of dynamics, e.g. friction, single control strategy may be inadequate. To handel varying task contexts, robots operating in human centric environment need to be equipped with multiple strategies. In the next section we give a brief overview of the multiple model approach (modular approach).


\subsection{Modular Approach}
% Some manipulation modelling method. drawback. You must survey other approaches to model multiple sensori-motor loops (also called motor program, motor primitives, behaviors, etc) and switching across these models, and then justify the use of Mosaic

%% Internal model
%In the study of human motor control, internal model is one of the most evidently supported hypothesis. It postulates a neuron process that simulates output of the motor system and the environment~\citep{kawato1999internal}. It's applications in robot control have been explored by many researchers. Various types of internal models are built for different tasks~\citep{sciavicco2000modelling,jordan1992forward}.

% Adaptive
Modular approach is used in adaptive control and its benefit has been long discussed~\citep{jacobs1991adaptive,narendra1997adaptive}.
In manipulation tasks, context changing is a common phenomenon due to object interactions. These changes are often rapid or discontinuous. Classic adaptive control approaches such as model identification~\citep{khalil2004modeling} are inadequate for these tasks, as instability or error may occur during the optimization of the model variables. To fast adapt, the multiple model approach~\citep{narendra1995adaptation}, referred as modular approach here, is proposed. In this approach, multiple controllers are designed, each of which in charge of a certain task context. During control, the task context is estimated online and the corresponding controllers are activated. Some recent work~\citep{fekri2007robust,kuipers2010multiple} presents promising modular based approaches. It has also been shown to be an effective architecture of building intelligent systems~\citep{bryson2004modular}. In robotics, it is particular useful for tasks in non-stationary environments~\citep{sugimoto2012emosaic}.

% Modular - human MOSAIC

%%The excellent ability of human to manipulate different objects in different contexts and to quickly adapt to change of contexts suggested that our central nervous system (CNS) maintains multiple internal models            of outside environments, rather than a single internal model that adapts to new environment~\citep{neilson1985acquisition}.
%Based on the concept of modularity, the Modular selection and identification for control (MOSAIC) architecture was proposed to explain the motor control strategy of the CNS~\citep{wolpert1998multiple}. According to this hypothesis, during the motor control process, the brain quickly select the most appropriate modules according to the current environment context and use them to generate an appropriate motor command to react to the environment~\citep{haruno2001mosaic}.

% Our approach
The modular approach we take is inspired from MOSAIC~\citep{haruno2001mosaic}. MOSAIC (Modular selection and identification for control) is a paradigm of multiple module control, where each module is composed of a forward model and an inverse model. The forward models are responsible for estimating the task context in real time, and the inverse models are used to generate appropriate motor command for the current context. The inverse models are weighted by the accuracy of the estimations of their corresponding forward models. The final motor command is the linear combination of the commands factored by their weights.

We take the paradigm of MOSAIC but implement the multiple modules model in our own manner. In the early work, \citet{wolpert1998multiple} use Artificial Neural Network (ANN) to encode the internal models, i.e. the forward models and the inverse models. The variance of a forward model, which decides how much the multiple modules collaborate, has to be manually tuned. The later work~\citep{haruno2001mosaic} fixes this hand tuning problem by modeling the transition between modules by a Hidden Markov Model (HMM) and optimizing the variance with the Expectation Maximization algorithm (EM). In this method the forward models are approximated by linear systems.
To solve the hand tuning problem of the variance but do not restrict the complexity of the internal models, we encode our internal models with the Gaussian Mixture Model (GMM)~\citep{cohn1996active}.
Training the GMM by the EM algorithm, we compute the optimal values of the models' parameters. GMM has been shown to be an efficient model in capturing the nonlinearity of data~\citep{calinon2007incremental,sauser2011iterative,huang2013learning}, this allows us to approximate more complex internal models.

%We take this paradigm and model our internal models by GMM. Training GMM with the Expectation Maximization algorithm (EM), we estimate the optimal values of the model parameters. Compare to the early work~\citep{wolpert1998multiple} which use Neural Network and has to manually tune the variance of each forward model, GMM has the advantage of automatically computing the all the model parameters. Later work~\citep{haruno2001mosaic} fixes the hand tuning problem by modeling with Hidden Markov Model (HMM) and optimize the model with EM. With this method the forward models are assumed to be linear. In our approach, GMM allows non-linear system to be modeled. Figure.~\ref{fig:control} illustrates the workflow of our approach. Compare to the switching modular method~\citep{narendra1997adaptive}, i.e. only one module will be activated and used to generate motor command, the linear combination of the modules requires less number of modules to approximate the system dynamics.
%The main reason is that neuron network can not directly estimate the likelihood of one query point. With NN, the the variance in each forward model, which is an essential variable to control how much the modules  cooperate, has to be hand tuned. .


In another work the forward model and inverse model are united to a single model~\citep{petkos2006learning}. For that particular task the action ($a_t$) taking the current task state ($s_t$) to the desired task state ($s_{t+1}$) is always unique. However, in many cases this mapping is not unique and hence the inverse model has to include extra variables in order to resolve the non-uniqueness. To take a more general approach, we build the forward and inverse model separately.
%However this model does not provide a method to find out number of models needed in tasks. %and the inverse model represented by the joint distribution will potentially produce an invalid command that average all possible solutions.

In our model the final motor command is the sum of the outputs of all modules. Compare to the switching modular method~\citep{narendra1997adaptive}, where only one module will be activated to generate motor command per time step, our approach requires less number of modules to approximate the system dynamics.




Despite the many discussions of the modular approach, its application in robotics is not yet wide-spread. One main challenge is how to modularize a given task, i.e. determine the number of modules and decompose the task. Similar problem is studied in the research of motion primitives. \citet{kulic2008incremental} use a hierarchical clustering method to extract primitives from human motion sequence. Different cut off parameters are tested to evaluate the trade off effect between facilitating quick group formation and introducing misclassification. Our modularize approach is similar to this and one step further. We cluster the demonstration data with an hierarchical method and regard each cluster as one module. Instead of hand tuning the cut off parameter, we determine its value by the variance of the data. This provides us with a proper grouping of the data, which can generate proper motor command for control.

Figure.~\ref{fig:control} illustrates the workflow of our approach. To the best of our knowledge, our work is the first realization of the modular approach in learning an object manipulation task with a real robot.


%We tackle this problem by a data driven approach: This solution can be applied to modularize many manipulation tasks. A similar clustering method has been applied to
% In our approach, the cut off parameter is determined by the variance of the data and hence avoid this step.

%Indeed, neuroscience evidence suggests that animal brain sum modular stimulates of muscles to generate different motions~\citep{mussa1994linear}.


%It is particularly useful to use learning to approximate internal models for motor control when the analytical model of the system dynamics is not easy to deduce.
%
%
%%Though the MOSAIC has gained a large concerns in neuroscience community, this approach is not widely used in robot control.
%
%Imitation learning has been an active topic of research in the last decade. It speeds up robot learning with the demonstrator showing the constraints of the tasks.

%The approach we take is a modular approach inspired from MOSAIC~\citep{haruno2001mosaic}. In MOSAIC, each dynamic system context is encoded by a pair of forward and inverse models. At each time step, the forward models estimate the current context and compare it with the actually context. The accuracy of the estimation decided the weight of the corresponding inverse models. The final motor command is the linear combination of the commands generated from each inverse models factored by their weights. The linear combination, rather than switch, of the models requires less number of models to approximate the system dynamics. Indeed, neuroscience evidence suggests that human brain mix modular stimulates of muscles to generate new motions. Our work focus on learning human's strategy of adaptive control on a modular base. To the best of our knowledge, this is the first realization of the multiple model control in an object manipulation task with a real robot, learnt from human demonstration.
%It can be used for solving nonlinear and non-stationary control problem.



%learning from human demonstration approach.


%
%Scientist has long been fascinated by human adaptive motor control ability and wondering the mechanism of it. One of the most evidently supported hypothesis is the multiple model~\citep{neilson1985acquisition}. %~\citep{haruno2001mosaic}



